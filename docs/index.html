<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>FastRText â€¢ FastRText</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">FastRText</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="/index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/pommedeterresautee/FastRText">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="contents col-md-9">
    <div id="fastrtext" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#fastrtext" class="anchor"></a>FastRText</h1></div>

<p>R wrapper for <a href="https://github.com/facebookresearch/fastText">fastText</a> C++ code from Facebook.</p>
<p>fastText is a library for efficient learning of word representations and sentence classification.</p>
<p><img src="https://github.com/pommedeterresautee/FastRText/raw/master/tools/fasttext-logo-color-web.png" alt="fastText logo"></p>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>You can install the package from Github.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages("devtools")</span>
devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"pommedeterresautee/FastRText"</span>)</code></pre></div>
</div>
<div id="api" class="section level2">
<h2 class="hasAnchor">
<a href="#api" class="anchor"></a>API</h2>
<p>The API has been made very light:</p>
<ul>
<li>
<code>load_model</code>: load an existing model ;</li>
<li>
<code>execute</code>: execute any command supported by the client ;</li>
<li>
<code>predict</code>: return predictions and their probability (supervised)</li>
<li>
<code>get_dictionary</code>: return list of words learned (unsupervised) ;</li>
<li>
<code>get_labels</code>: return list of labels learned (supervised) ;</li>
<li>
<code>get_parameters</code>: return the parameters used for training ;</li>
<li>
<code>get_word_distance</code>: cosine distance between 2 vectors ;</li>
<li>
<code>get_word_vectors</code>: return vectors in a <code>list</code> related to a <code>character</code> vector of words/labels.</li>
</ul>
<p>Detailed explanations are available on:<br><a href="https://pommedeterresautee.github.io/FastRText/" class="uri">https://pommedeterresautee.github.io/FastRText/</a></p>
<div id="supervised-learning-text-classification" class="section level3">
<h3 class="hasAnchor">
<a href="#supervised-learning-text-classification" class="anchor"></a>Supervised learning (text classification)</h3>
<p>Data for a multi-class task are embedded in this package.<br>
Below we will learn a model and then measure the accuracy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">library</span>(FastRText)
  
    <span class="kw">data</span>(<span class="st">"train_sentences"</span>)
    <span class="kw">data</span>(<span class="st">"test_sentences"</span>)
    
    <span class="co"># prepare data</span>
    tmp_file_model &lt;-<span class="st"> </span><span class="kw">tempfile</span>()
    
    train_labels &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">"__label__"</span>, train_sentences[,<span class="st">"class.text"</span>])
    train_texts &lt;-<span class="st"> </span><span class="kw">tolower</span>(train_sentences[,<span class="st">"text"</span>])
    train_to_write &lt;-<span class="st"> </span><span class="kw">paste</span>(train_labels, train_texts)
    train_tmp_file_txt &lt;-<span class="st"> </span><span class="kw">tempfile</span>()
    <span class="kw">writeLines</span>(<span class="dt">text =</span> train_to_write, <span class="dt">con =</span> train_tmp_file_txt)
    
    test_labels &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">"__label__"</span>, test_sentences[,<span class="st">"class.text"</span>])
    test_texts &lt;-<span class="st"> </span><span class="kw">tolower</span>(test_sentences[,<span class="st">"text"</span>])
    test_to_write &lt;-<span class="st"> </span><span class="kw">paste</span>(test_labels, test_texts)
    
    <span class="co"># learn model</span>
    <span class="kw"><a href="reference/execute.html">execute</a></span>(<span class="dt">commands =</span> <span class="kw">c</span>(<span class="st">"supervised"</span>, <span class="st">"-input"</span>, train_tmp_file_txt, <span class="st">"-output"</span>, tmp_file_model, <span class="st">"-dim"</span>, <span class="dv">20</span>, <span class="st">"-lr"</span>, <span class="dv">1</span>, <span class="st">"-epoch"</span>, <span class="dv">20</span>, <span class="st">"-wordNgrams"</span>, <span class="dv">2</span>, <span class="st">"-verbose"</span>, <span class="dv">1</span>))</code></pre></div>
<pre><code>    Read 0M words
    Number of words:  5060
    Number of labels: 15
    Progress: 100.0%  words/sec/thread: 1855760  lr: 0.000000  loss: 0.312088  eta: 0h0m </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="co"># load model</span>
    model &lt;-<span class="st"> </span><span class="kw"><a href="reference/load_model.html">load_model</a></span>(tmp_file_model)
    
    <span class="co"># prediction are returned as a list with words and probabilities</span>
    predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">sentences =</span> test_to_write)
    <span class="kw">print</span>(<span class="kw">head</span>(predictions, <span class="dv">5</span>))</code></pre></div>
<pre><code>    [[1]]
    __label__OWNX 
        0.9980469 
    
    [[2]]
    __label__MISC 
        0.9667969 
    
    [[3]]
    __label__MISC 
        0.9863281 
    
    [[4]]
    __label__OWNX 
        0.9082031 
    
    [[5]]
    __label__AIMX 
         0.984375 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="co"># Compute accuracy</span>
    <span class="kw">mean</span>(<span class="kw">sapply</span>(predictions, names) <span class="op">==</span><span class="st"> </span>test_labels)
    
    <span class="co"># because there is only one category by observation, hamming loss will be the same</span>
    <span class="kw"><a href="reference/get_hamming_loss.html">get_hamming_loss</a></span>(<span class="kw">as.list</span>(test_labels), predictions)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    [<span class="dv">1</span>] <span class="fl">0.82</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="co"># test predictions</span>
    predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">sentences =</span> test_to_write)
    <span class="kw">print</span>(<span class="kw">head</span>(predictions, <span class="dv">5</span>))</code></pre></div>
<pre><code>    [[1]]
    __label__OWNX 
        0.9980469 
    
    [[2]]
    __label__MISC 
        0.9667969 
    
    [[3]]
    __label__MISC 
        0.9863281 
    
    [[4]]
    __label__OWNX 
        0.9082031 
    
    [[5]]
    __label__AIMX 
         0.984375 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="co"># free memory</span>
    <span class="kw">unlink</span>(train_tmp_file_txt)
    <span class="kw">unlink</span>(tmp_file_model)
    <span class="kw">rm</span>(model)
    <span class="kw">gc</span>()</code></pre></div>
</div>
<div id="unsupervised-learning-word-representation" class="section level3">
<h3 class="hasAnchor">
<a href="#unsupervised-learning-word-representation" class="anchor"></a>Unsupervised learning (word representation)</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">library</span>(FastRText)
    
    <span class="kw">data</span>(<span class="st">"train_sentences"</span>)
    <span class="kw">data</span>(<span class="st">"test_sentences"</span>)
    texts &lt;-<span class="st"> </span><span class="kw">tolower</span>(train_sentences[,<span class="st">"text"</span>])
    tmp_file_txt &lt;-<span class="st"> </span><span class="kw">tempfile</span>()
    tmp_file_model &lt;-<span class="st"> </span><span class="kw">tempfile</span>()
    <span class="kw">writeLines</span>(<span class="dt">text =</span> texts, <span class="dt">con =</span> tmp_file_txt)
    <span class="kw"><a href="reference/execute.html">execute</a></span>(<span class="dt">commands =</span> <span class="kw">c</span>(<span class="st">"skipgram"</span>, <span class="st">"-input"</span>, tmp_file_txt, <span class="st">"-output"</span>, tmp_file_model, <span class="st">"-verbose"</span>, <span class="dv">1</span>))</code></pre></div>
<pre><code>    Read 0M words
    Number of words:  2061
    Number of labels: 0
    Progress: 100.0%  words/sec/thread: 18608  lr: 0.000000  loss: 2.717084  eta: 0h0m</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    model &lt;-<span class="st"> </span><span class="kw"><a href="reference/load_model.html">load_model</a></span>(tmp_file_model)
   
    <span class="co"># test word extraction</span>
    dict &lt;-<span class="st"> </span><span class="kw"><a href="reference/get_dictionary.html">get_dictionary</a></span>(model)
    <span class="kw">print</span>(<span class="kw">head</span>(dict, <span class="dv">5</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    [<span class="dv">1</span>] <span class="st">"the"</span>  <span class="st">"&lt;/s&gt;"</span> <span class="st">"of"</span>   <span class="st">"to"</span>   <span class="st">"and"</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co"># print vector</span>
  <span class="kw">print</span>(<span class="kw"><a href="reference/get_word_vectors.html">get_word_vectors</a></span>(model, <span class="kw">c</span>(<span class="st">"time"</span>, <span class="st">"timing"</span>)))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="op">$</span>time
      [<span class="dv">1</span>]  <span class="fl">0.1296210885</span>  <span class="fl">0.1316468269</span>  <span class="fl">0.0007626821</span>  <span class="fl">0.0356817469</span>  <span class="fl">0.2006593198</span> <span class="op">-</span><span class="fl">0.0460157879</span>  <span class="fl">0.0231023580</span> <span class="op">-</span><span class="fl">0.0233316422</span>  <span class="fl">0.1362834424</span> <span class="op">-</span><span class="fl">0.0420252681</span>
     [<span class="dv">11</span>] <span class="op">-</span><span class="fl">0.0655319244</span> <span class="op">-</span><span class="fl">0.0762185380</span> <span class="op">-</span><span class="fl">0.1488197595</span> <span class="op">-</span><span class="fl">0.1035384983</span> <span class="op">-</span><span class="fl">0.0845064148</span>  <span class="fl">0.2970835268</span> <span class="op">-</span><span class="fl">0.0226780772</span> <span class="op">-</span><span class="fl">0.1043037027</span> <span class="op">-</span><span class="fl">0.0474399552</span>  <span class="fl">0.2767507732</span>
     [<span class="dv">21</span>] <span class="op">-</span><span class="fl">0.1631491482</span>  <span class="fl">0.0246577058</span> <span class="op">-</span><span class="fl">0.0510919876</span>  <span class="fl">0.1415337175</span> <span class="op">-</span><span class="fl">0.0186830349</span>  <span class="fl">0.0277102590</span>  <span class="fl">0.2989047170</span> <span class="op">-</span><span class="fl">0.1091243699</span>  <span class="fl">0.2127154171</span>  <span class="fl">0.1774759591</span>
     [<span class="dv">31</span>] <span class="op">-</span><span class="fl">0.2118884921</span>  <span class="fl">0.1580083966</span> <span class="op">-</span><span class="fl">0.2573904097</span>  <span class="fl">0.0720630288</span>  <span class="fl">0.1223027334</span> <span class="op">-</span><span class="fl">0.1067906320</span> <span class="op">-</span><span class="fl">0.1770184636</span> <span class="op">-</span><span class="fl">0.1367645562</span> <span class="op">-</span><span class="fl">0.1797255427</span> <span class="op">-</span><span class="fl">0.2507483065</span>
     [<span class="dv">41</span>] <span class="op">-</span><span class="fl">0.0737731382</span> <span class="op">-</span><span class="fl">0.0335764810</span>  <span class="fl">0.4934033751</span>  <span class="fl">0.0927968696</span> <span class="op">-</span><span class="fl">0.1988559216</span> <span class="op">-</span><span class="fl">0.1831049174</span>  <span class="fl">0.0014060348</span>  <span class="fl">0.2465015799</span> <span class="op">-</span><span class="fl">0.0966282785</span>  <span class="fl">0.0663930923</span>
     [<span class="dv">51</span>]  <span class="fl">0.1156903356</span> <span class="op">-</span><span class="fl">0.0581681095</span>  <span class="fl">0.1633448750</span>  <span class="fl">0.0965265408</span> <span class="op">-</span><span class="fl">0.2318589687</span> <span class="op">-</span><span class="fl">0.0084880590</span> <span class="op">-</span><span class="fl">0.0637115017</span> <span class="op">-</span><span class="fl">0.3696584404</span>  <span class="fl">0.0428320728</span>  <span class="fl">0.0274929013</span>
     [<span class="dv">61</span>] <span class="op">-</span><span class="fl">0.1674125642</span>  <span class="fl">0.0492200330</span> <span class="op">-</span><span class="fl">0.0935025662</span>  <span class="fl">0.4473278522</span>  <span class="fl">0.1401670724</span> <span class="op">-</span><span class="fl">0.0925518200</span>  <span class="fl">0.0110784201</span> <span class="op">-</span><span class="fl">0.2160260379</span> <span class="op">-</span><span class="fl">0.0858220831</span>  <span class="fl">0.0785235688</span>
     [<span class="dv">71</span>] <span class="op">-</span><span class="fl">0.0083946604</span>  <span class="fl">0.0849706084</span> <span class="op">-</span><span class="fl">0.0517802760</span> <span class="op">-</span><span class="fl">0.2749955654</span> <span class="op">-</span><span class="fl">0.0682966709</span>  <span class="fl">0.0041731247</span>  <span class="fl">0.0097561805</span> <span class="op">-</span><span class="fl">0.0087426975</span>  <span class="fl">0.0818234086</span>  <span class="fl">0.0333902463</span>
     [<span class="dv">81</span>] <span class="op">-</span><span class="fl">0.0850559697</span>  <span class="fl">0.1362940371</span> <span class="op">-</span><span class="fl">0.0933185294</span>  <span class="fl">0.1068129763</span> <span class="op">-</span><span class="fl">0.1092673689</span> <span class="op">-</span><span class="fl">0.1502138227</span>  <span class="fl">0.0475843176</span>  <span class="fl">0.1930907071</span> <span class="op">-</span><span class="fl">0.1171457469</span>  <span class="fl">0.0033585809</span>
     [<span class="dv">91</span>]  <span class="fl">0.1949805468</span>  <span class="fl">0.1669725925</span>  <span class="fl">0.1696546674</span> <span class="op">-</span><span class="fl">0.1804515570</span> <span class="op">-</span><span class="fl">0.1499735862</span>  <span class="fl">0.0847207233</span> <span class="op">-</span><span class="fl">0.1824831218</span> <span class="op">-</span><span class="fl">0.2149232626</span> <span class="op">-</span><span class="fl">0.1255764067</span> <span class="op">-</span><span class="fl">0.0145111699</span>
    
    <span class="op">$</span>timing
      [<span class="dv">1</span>]  <span class="fl">0.160078079</span>  <span class="fl">0.089299947</span> <span class="op">-</span><span class="fl">0.028443312</span>  <span class="fl">0.087577075</span>  <span class="fl">0.197204530</span> <span class="op">-</span><span class="fl">0.046088688</span>  <span class="fl">0.014435329</span>  <span class="fl">0.010740009</span>  <span class="fl">0.157881737</span> <span class="op">-</span><span class="fl">0.041626919</span> <span class="op">-</span><span class="fl">0.087656625</span>
     [<span class="dv">12</span>] <span class="op">-</span><span class="fl">0.077158570</span> <span class="op">-</span><span class="fl">0.117233768</span> <span class="op">-</span><span class="fl">0.084212191</span> <span class="op">-</span><span class="fl">0.033463344</span>  <span class="fl">0.268052191</span>  <span class="fl">0.024618769</span> <span class="op">-</span><span class="fl">0.062947571</span> <span class="op">-</span><span class="fl">0.038740944</span>  <span class="fl">0.274398685</span> <span class="op">-</span><span class="fl">0.180828378</span>  <span class="fl">0.032722849</span>
     [<span class="dv">23</span>] <span class="op">-</span><span class="fl">0.074779101</span>  <span class="fl">0.169604152</span>  <span class="fl">0.001532920</span>  <span class="fl">0.011797827</span>  <span class="fl">0.298075169</span> <span class="op">-</span><span class="fl">0.148507968</span>  <span class="fl">0.236132696</span>  <span class="fl">0.201769084</span> <span class="op">-</span><span class="fl">0.253632784</span>  <span class="fl">0.141390175</span> <span class="op">-</span><span class="fl">0.358699590</span>
     [<span class="dv">34</span>]  <span class="fl">0.139938250</span>  <span class="fl">0.060195319</span> <span class="op">-</span><span class="fl">0.084415935</span> <span class="op">-</span><span class="fl">0.216627970</span> <span class="op">-</span><span class="fl">0.135275722</span> <span class="op">-</span><span class="fl">0.168502375</span> <span class="op">-</span><span class="fl">0.309166789</span> <span class="op">-</span><span class="fl">0.067674220</span>  <span class="fl">0.021249762</span>  <span class="fl">0.536724389</span>  <span class="fl">0.111997329</span>
     [<span class="dv">45</span>] <span class="op">-</span><span class="fl">0.247994825</span> <span class="op">-</span><span class="fl">0.179069623</span> <span class="op">-</span><span class="fl">0.010358712</span>  <span class="fl">0.212842971</span> <span class="op">-</span><span class="fl">0.142138332</span>  <span class="fl">0.103004083</span>  <span class="fl">0.134464145</span> <span class="op">-</span><span class="fl">0.047396421</span>  <span class="fl">0.254947871</span>  <span class="fl">0.076861322</span> <span class="op">-</span><span class="fl">0.288775802</span>
     [<span class="dv">56</span>]  <span class="fl">0.013832947</span> <span class="op">-</span><span class="fl">0.091028608</span> <span class="op">-</span><span class="fl">0.401299775</span>  <span class="fl">0.037415996</span>  <span class="fl">0.043258362</span> <span class="op">-</span><span class="fl">0.194530174</span>  <span class="fl">0.044848040</span> <span class="op">-</span><span class="fl">0.110459305</span>  <span class="fl">0.459034413</span>  <span class="fl">0.105486415</span> <span class="op">-</span><span class="fl">0.128112644</span>
     [<span class="dv">67</span>] <span class="op">-</span><span class="fl">0.011169771</span> <span class="op">-</span><span class="fl">0.246604726</span> <span class="op">-</span><span class="fl">0.136286691</span>  <span class="fl">0.064792447</span>  <span class="fl">0.004366267</span>  <span class="fl">0.066067092</span> <span class="op">-</span><span class="fl">0.043443765</span> <span class="op">-</span><span class="fl">0.263737917</span> <span class="op">-</span><span class="fl">0.084394999</span>  <span class="fl">0.033850316</span>  <span class="fl">0.045276560</span>
     [<span class="dv">78</span>] <span class="op">-</span><span class="fl">0.069755353</span>  <span class="fl">0.042322587</span>  <span class="fl">0.015659215</span> <span class="op">-</span><span class="fl">0.058141325</span>  <span class="fl">0.120230742</span> <span class="op">-</span><span class="fl">0.131767645</span>  <span class="fl">0.110347047</span> <span class="op">-</span><span class="fl">0.151947677</span> <span class="op">-</span><span class="fl">0.201012269</span>  <span class="fl">0.045367155</span>  <span class="fl">0.210986614</span>
     [<span class="dv">89</span>] <span class="op">-</span><span class="fl">0.127198741</span>  <span class="fl">0.021938557</span>  <span class="fl">0.247432858</span>  <span class="fl">0.160363480</span>  <span class="fl">0.148728162</span> <span class="op">-</span><span class="fl">0.168013781</span> <span class="op">-</span><span class="fl">0.169050500</span>  <span class="fl">0.132359743</span> <span class="op">-</span><span class="fl">0.186982766</span> <span class="op">-</span><span class="fl">0.232297495</span> <span class="op">-</span><span class="fl">0.124483496</span>
    [<span class="dv">100</span>]  <span class="fl">0.010415908</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co"># test word distance</span>
  <span class="kw"><a href="reference/get_word_distance.html">get_word_distance</a></span>(model, <span class="st">"time"</span>, <span class="st">"timing"</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">           [,<span class="dv">1</span>]
[<span class="dv">1</span>,] <span class="fl">0.01769618</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co"># free memory</span>
  <span class="kw">unlink</span>(tmp_file_txt)
  <span class="kw">unlink</span>(tmp_file_model)
  <span class="kw">rm</span>(model)
  <span class="kw">gc</span>()</code></pre></div>
</div>
</div>
<div id="command-list-to-use-with-execute-function" class="section level2">
<h2 class="hasAnchor">
<a href="#command-list-to-use-with-execute-function" class="anchor"></a>Command list to use with execute() function</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="reference/print_help.html">print_help</a></span>()</code></pre></div>
<pre><code>The following arguments are mandatory:
  -input              training file path
  -output             output file path

  The following arguments are optional:
  -verbose            verbosity level [2]

  The following arguments for the dictionary are optional:
  -minCount           minimal number of word occurences [5]
  -minCountLabel      minimal number of label occurences [0]
  -wordNgrams         max length of word ngram [1]
  -bucket             number of buckets [2000000]
  -minn               min length of char ngram [3]
  -maxn               max length of char ngram [6]
  -t                  sampling threshold [0.0001]
  -label              labels prefix [__label__]

  The following arguments for training are optional:
  -lr                 learning rate [0.05]
  -lrUpdateRate       change the rate of updates for the learning rate [100]
  -dim                size of word vectors [100]
  -ws                 size of the context window [5]
  -epoch              number of epochs [5]
  -neg                number of negatives sampled [5]
  -loss               loss function {ns, hs, softmax} [ns]
  -thread             number of threads [12]
  -pretrainedVectors  pretrained word vectors for supervised learning []
  -saveOutput         whether output params should be saved [0]

  The following arguments for quantization are optional:
  -cutoff             number of words and ngrams to retain [0]
  -retrain            finetune embeddings if a cutoff is applied [0]
  -qnorm              quantizing the norm separately [0]
  -qout               quantizing the classifier [0]
  -dsub               size of each sub-vector [2]</code></pre>
</div>
<div id="alternatives" class="section level2">
<h2 class="hasAnchor">
<a href="#alternatives" class="anchor"></a>Alternatives</h2>
<ul>
<li>Why not use the command line client?<br>
</li>
<li>You can call the client from the client using <code>system("fastext ...")</code>.<br>
</li>
<li>To get prediction, you will need to write file, make predictions from the command line, then read the results.<br>
</li>
<li>FastRText makes your life easier by making all these operations in memory.<br>
</li>
<li>It takes less time, and use less commands.</li>
<li><p>Easy to install from R directly.</p></li>
<li>Why not use <a href="https://github.com/mlampros/fastTextR/">fastTextR</a> ?</li>
<li>FastRText implements both supervised and unsupervised parts of fasttext.</li>
<li>Predictions can be done in memory (unlike fastTextR)</li>
<li><p>fastText original source code embedded in fastTextR is not up to date (miss many new features, bug fixes since January 2017) because original source code has been modified (not the case of this package)</p></li>
</ul>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Please cite <a href="#enriching-word-vectors-with-subword-information">1</a> if using this code for learning word representations or <a href="#bag-of-tricks-for-efficient-text-classification">2</a> if using for text classification.</p>
<div id="enriching-word-vectors-with-subword-information" class="section level3">
<h3 class="hasAnchor">
<a href="#enriching-word-vectors-with-subword-information" class="anchor"></a>Enriching Word Vectors with Subword Information</h3>
<p>[1] P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, <a href="https://arxiv.org/abs/1607.04606"><em>Enriching Word Vectors with Subword Information</em></a></p>
<pre><code>@article{bojanowski2016enriching,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}</code></pre>
</div>
<div id="bag-of-tricks-for-efficient-text-classification" class="section level3">
<h3 class="hasAnchor">
<a href="#bag-of-tricks-for-efficient-text-classification" class="anchor"></a>Bag of Tricks for Efficient Text Classification</h3>
<p>[2] A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, <a href="https://arxiv.org/abs/1607.01759"><em>Bag of Tricks for Efficient Text Classification</em></a></p>
<pre><code>@article{joulin2016bag,
  title={Bag of Tricks for Efficient Text Classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}</code></pre>
</div>
<div id="fasttext-zip-compressing-text-classification-models" class="section level3">
<h3 class="hasAnchor">
<a href="#fasttext-zip-compressing-text-classification-models" class="anchor"></a>FastText.zip: Compressing text classification models</h3>
<p>[3] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. JÃ©gou, T. Mikolov, <a href="https://arxiv.org/abs/1612.03651"><em>FastText.zip: Compressing text classification models</em></a></p>
<pre><code>@article{joulin2016fasttext,
  title={FastText.zip: Compressing text classification models},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\'e}gou, H{\'e}rve and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1612.03651},
  year={2016}
}</code></pre>
<p>(* These authors contributed equally.)</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3" id="sidebar">
    <h2>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/pommedeterresautee/FastRText">https://â€‹github.com/â€‹pommedeterresautee/â€‹FastRText</a>
</li>
<li>Report a bug at <br><a href="https://github.com/pommedeterresautee/FastRText/issues">https://â€‹github.com/â€‹pommedeterresautee/â€‹FastRText/â€‹issues</a>
</li>
</ul>
<h2>License</h2>
<p><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file <a href="LICENSE.html">LICENSE</a></p>
<h2>Developers</h2>
<ul class="list-unstyled">
<li>MichaÃ«l Benesty <br><small class="roles"> Author, maintainer </small> </li>
</ul>
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://travis-ci.org/pommedeterresautee/FastRText"><img src="https://travis-ci.org/pommedeterresautee/FastRText.svg?branch=master" alt="Travis-CI Build Status"></a></li>
<li><a href="https://ci.appveyor.com/project/pommedeterresautee/FastRText"><img src="https://ci.appveyor.com/api/projects/status/github/pommedeterresautee/FastRText?branch=master&amp;svg=true" alt="AppVeyor Build Status"></a></li>
<li><a href="https://codecov.io/gh/pommedeterresautee/FastRText"><img src="https://codecov.io/gh/pommedeterresautee/FastRText/branch/master/graph/badge.svg" alt="codecov"></a></li>
</ul>
</div>
</div>


      <footer><div class="copyright">
  <p>Developed by MichaÃ«l Benesty.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
